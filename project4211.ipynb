{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "project4211.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferdyanggara/indonlu/blob/master/project4211.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nfPaiUkzhyj"
      },
      "source": [
        "# Finetuning Twitter SA\n",
        "TwitterSA is a Sentiment Analysis dataset with 3 possible labels: `positive`, `negative`, `irrelevant` and `neutral`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_hsChcpENA-",
        "outputId": "eb8a6811-4709-42e6-91c3-03dc2c39552f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ2KP2R5c6SA"
      },
      "source": [
        "# Installing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v-EyPwkzEBPQ",
        "outputId": "22530cf3-9b26-4712-a761-8c07c9b3d294"
      },
      "source": [
        "pip install -r drive/MyDrive/project4211/requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==2.9.0\n",
            "  Downloading transformers-2.9.0-py3-none-any.whl (635 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635 kB 594 kB/s \n",
            "\u001b[?25hCollecting pandas==1.3.4\n",
            "  Downloading pandas-1.3.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.3 MB 37.3 MB/s \n",
            "\u001b[?25hCollecting numpy==1.17.4\n",
            "  Downloading numpy-1.17.4-cp37-cp37m-manylinux1_x86_64.whl (20.0 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20.0 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.1\n",
            "  Downloading scikit_learn-0.22.1-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.0 MB 10.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.15.0\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 412.3 MB 25 kB/s \n",
            "\u001b[?25hCollecting torch==1.5.0\n",
            "  Downloading torch-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (752.0 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 752.0 MB 9.4 kB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.5 MB 34.7 MB/s \n",
            "\u001b[?25hCollecting unidecode==1.1.1\n",
            "  Downloading Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 238 kB 22.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0->-r drive/MyDrive/project4211/requirements.txt (line 1)) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895 kB 39.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "  Downloading tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.6 MB 22.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0->-r drive/MyDrive/project4211/requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0->-r drive/MyDrive/project4211/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0->-r drive/MyDrive/project4211/requirements.txt (line 1)) (4.62.3)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2 MB 51.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.4->-r drive/MyDrive/project4211/requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.4->-r drive/MyDrive/project4211/requirements.txt (line 2)) (2018.9)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.1->-r drive/MyDrive/project4211/requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.1->-r drive/MyDrive/project4211/requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (1.1.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (1.13.3)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8 MB 40.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (1.42.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 503 kB 38.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (0.37.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0->-r drive/MyDrive/project4211/requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (3.6.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0->-r drive/MyDrive/project4211/requirements.txt (line 5)) (1.5.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0->-r drive/MyDrive/project4211/requirements.txt (line 1)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0->-r drive/MyDrive/project4211/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0->-r drive/MyDrive/project4211/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0->-r drive/MyDrive/project4211/requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.0->-r drive/MyDrive/project4211/requirements.txt (line 1)) (7.1.2)\n",
            "Building wheels for collected packages: nltk, gast\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449922 sha256=13eba26923ac7046d8990d69fb1d934ade0701b6528deab3cb2c1eade1dcfd7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=6a2decdf23e565ffa2777b77b7d257c30e97d1f5d145875e376547f42b483fb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built nltk gast\n",
            "Installing collected packages: numpy, tokenizers, tensorflow-estimator, tensorboard, sentencepiece, sacremoses, keras-applications, gast, unidecode, transformers, torch, tensorflow, scikit-learn, pandas, nltk\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.5.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.5.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.5.0 which is incompatible.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.6 requires numpy>=1.18.5, but you have numpy 1.17.4 which is incompatible.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\n",
            "jaxlib 0.1.74+cuda11.cudnn805 requires numpy>=1.18, but you have numpy 1.17.4 which is incompatible.\n",
            "jax 0.2.25 requires numpy>=1.18, but you have numpy 1.17.4 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 nltk-3.4.5 numpy-1.17.4 pandas-1.3.4 sacremoses-0.0.46 scikit-learn-0.22.1 sentencepiece-0.1.96 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1 tokenizers-0.7.0 torch-1.5.0 transformers-2.9.0 unidecode-1.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_OCbgSUcoad"
      },
      "source": [
        "# Import Statement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx5YR5-Szhyo"
      },
      "source": [
        "import os, sys\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABhmlCYg4tCz"
      },
      "source": [
        "import string\n",
        "import torch\n",
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b0zBxR14vKb"
      },
      "source": [
        "import itertools\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz1zs4W3c-uR"
      },
      "source": [
        "Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMCfew9Y8HPy"
      },
      "source": [
        "train = pd.read_csv('drive/MyDrive/project4211/twitter_training.csv', header=None)\n",
        "test = pd.read_csv('drive/MyDrive/project4211/twitter_validation.csv', header=None)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3wxlu2xdB0_"
      },
      "source": [
        "Dropping missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2jtQwnxHzmi"
      },
      "source": [
        "train.dropna(inplace=True)\n",
        "test.dropna(inplace=True)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXuyBIvddFyy"
      },
      "source": [
        "Splitting training and testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxkeVXQo9Gpj"
      },
      "source": [
        "train, valid = train_test_split(train, test_size=0.2, stratify=train.iloc[:,2])\n",
        "\n",
        "valid = valid.iloc[:, [2,3]]\n",
        "valid.columns = ['sentiment', 'text']\n",
        "\n",
        "train = train.iloc[:, [2,3]]\n",
        "train.columns = ['sentiment', 'text']\n",
        "\n",
        "test = test.iloc[:, [2,3]]\n",
        "test.columns = ['sentiment', 'text']"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQN47Y--dJkM"
      },
      "source": [
        "Store dataset in tsv format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6jPympB-2Md"
      },
      "source": [
        "train.to_csv(\"train.tsv\", sep=\"\\t\", index=False, header=None)\n",
        "valid.to_csv(\"valid.tsv\", sep=\"\\t\", index=False, header=None)\n",
        "test.to_csv(\"test.tsv\", sep=\"\\t\", index=False, header=None)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1WVrHkmdM8a"
      },
      "source": [
        "Dataset & Dataloader Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhzy8gob4j8U"
      },
      "source": [
        "class DocumentSentimentDataset(Dataset):\n",
        "    # Static constant variable\n",
        "    LABEL2INDEX = {'Positive': 0, 'Neutral': 1, 'Negative': 2, 'Irrelevant': 3}\n",
        "    INDEX2LABEL = {0: 'Positive', 1: 'Neutral', 2: 'Negative', 3: 'Irrelevant'}\n",
        "    NUM_LABELS = 4\n",
        "    \n",
        "    def load_dataset(self, path): \n",
        "        df = pd.read_csv(path, sep='\\t', header=None)\n",
        "        df.columns = ['sentiment','text']\n",
        "        df['sentiment'] = df['sentiment'].apply(lambda lab: self.LABEL2INDEX[lab])\n",
        "        return df\n",
        "    \n",
        "    def __init__(self, dataset_path, tokenizer, no_special_token=False, *args, **kwargs):\n",
        "        self.data = self.load_dataset(dataset_path)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.no_special_token = no_special_token\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        data = self.data.loc[index,:]\n",
        "        text, sentiment = data['text'], data['sentiment']\n",
        "        subwords = self.tokenizer.encode(text, add_special_tokens=not self.no_special_token)\n",
        "        return np.array(subwords), np.array(sentiment), data['text']\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)    \n",
        "        \n",
        "class DocumentSentimentDataLoader(DataLoader):\n",
        "    def __init__(self, max_seq_len=512, *args, **kwargs):\n",
        "        super(DocumentSentimentDataLoader, self).__init__(*args, **kwargs)\n",
        "        self.collate_fn = self._collate_fn\n",
        "        self.max_seq_len = max_seq_len\n",
        "        \n",
        "    def _collate_fn(self, batch):\n",
        "        batch_size = len(batch)\n",
        "        max_seq_len = max(map(lambda x: len(x[0]), batch))\n",
        "        max_seq_len = min(self.max_seq_len, max_seq_len)\n",
        "        \n",
        "        subword_batch = np.zeros((batch_size, max_seq_len), dtype=np.int64)\n",
        "        mask_batch = np.zeros((batch_size, max_seq_len), dtype=np.float32)\n",
        "        sentiment_batch = np.zeros((batch_size, 1), dtype=np.int64)\n",
        "        \n",
        "        seq_list = []\n",
        "        for i, (subwords, sentiment, raw_seq) in enumerate(batch):\n",
        "            subwords = subwords[:max_seq_len]\n",
        "            subword_batch[i,:len(subwords)] = subwords\n",
        "            mask_batch[i,:len(subwords)] = 1\n",
        "            sentiment_batch[i,0] = sentiment\n",
        "            \n",
        "            seq_list.append(raw_seq)\n",
        "            \n",
        "        return subword_batch, mask_batch, sentiment_batch, seq_list\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71qluKA94O_1"
      },
      "source": [
        "def document_sentiment_metrics_fn(list_hyp, list_label):\n",
        "    metrics = {}\n",
        "    metrics[\"ACC\"] = accuracy_score(list_label, list_hyp)\n",
        "    metrics[\"F1\"] = f1_score(list_label, list_hyp, average='macro')\n",
        "    metrics[\"REC\"] = recall_score(list_label, list_hyp, average='macro')\n",
        "    metrics[\"PRE\"] = precision_score(list_label, list_hyp, average='macro')\n",
        "    return metrics\n"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZX1w-gd4GLl"
      },
      "source": [
        "# Forward function for sequence classification\n",
        "def forward_sequence_classification(model, batch_data, i2w, is_test=False, device='cpu', **kwargs):\n",
        "    # Unpack batch data\n",
        "    if len(batch_data) == 3:\n",
        "        (subword_batch, mask_batch, label_batch) = batch_data\n",
        "        token_type_batch = None\n",
        "    elif len(batch_data) == 4:\n",
        "        (subword_batch, mask_batch, token_type_batch, label_batch) = batch_data\n",
        "    \n",
        "    # Prepare input & label\n",
        "    subword_batch = torch.LongTensor(subword_batch)\n",
        "    mask_batch = torch.FloatTensor(mask_batch)\n",
        "    token_type_batch = torch.LongTensor(token_type_batch) if token_type_batch is not None else None\n",
        "    label_batch = torch.LongTensor(label_batch)\n",
        "            \n",
        "    if device == \"cuda\":\n",
        "        subword_batch = subword_batch.cuda()\n",
        "        mask_batch = mask_batch.cuda()\n",
        "        token_type_batch = token_type_batch.cuda() if token_type_batch is not None else None\n",
        "        label_batch = label_batch.cuda()\n",
        "\n",
        "    # Forward model\n",
        "    outputs = model(subword_batch, attention_mask=mask_batch, token_type_ids=token_type_batch, labels=label_batch)\n",
        "    loss, logits = outputs[:2]\n",
        "    \n",
        "    # generate prediction & label list\n",
        "    list_hyp = []\n",
        "    list_label = []\n",
        "    hyp = torch.topk(logits, 1)[1]\n",
        "    for j in range(len(hyp)):\n",
        "        list_hyp.append(i2w[hyp[j].item()])\n",
        "        list_label.append(i2w[label_batch[j][0].item()])\n",
        "        \n",
        "    return loss, list_hyp, list_label\n"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBumLamtzhyp"
      },
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    \n",
        "def count_param(module, trainable=False):\n",
        "    if trainable:\n",
        "        return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "    else:\n",
        "        return sum(p.numel() for p in module.parameters())\n",
        "    \n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def metrics_to_string(metric_dict):\n",
        "    string_list = []\n",
        "    for key, value in metric_dict.items():\n",
        "        string_list.append('{}:{:.2f}'.format(key, value))\n",
        "    return ' '.join(string_list)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik5lipytzhyq"
      },
      "source": [
        "# Set random seed\n",
        "set_seed(26112021)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASK_X6L8zhyr"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsFqNJTDKAZa"
      },
      "source": [
        "# Load Tokenizer and Config\n",
        "tokenizer = BertTokenizer.from_pretrained('prajjwal1/bert-tiny')\n",
        "config = BertConfig.from_pretrained('prajjwal1/bert-tiny')\n",
        "config.num_labels = DocumentSentimentDataset.NUM_LABELS\n",
        "\n",
        "# Instantiate model\n",
        "model = BertForSequenceClassification.from_pretrained('prajjwal1/bert-tiny', config=config)\n",
        "\n"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QgFJvYJKE20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11fad8b3-8564-4aef-aeac-3715d5f3e1e7"
      },
      "source": [
        "model\n"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 128)\n",
              "      (token_type_embeddings): Embedding(2, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=128, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0uvnIZXKFjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da19c91-31c3-4851-cf95-ac622eda4756"
      },
      "source": [
        "count_param(model)\n"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4386436"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHpV9e5Nzhyu"
      },
      "source": [
        "# Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Olf7HlYTzhyv"
      },
      "source": [
        "train_dataset_path = './train.tsv'\n",
        "valid_dataset_path = './valid.tsv'\n",
        "test_dataset_path = './test.tsv'"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx2WUg67zhyw"
      },
      "source": [
        "train_dataset = DocumentSentimentDataset(train_dataset_path, tokenizer, lowercase=True)\n",
        "valid_dataset = DocumentSentimentDataset(valid_dataset_path, tokenizer, lowercase=True)\n",
        "test_dataset = DocumentSentimentDataset(test_dataset_path, tokenizer, lowercase=True)\n",
        "\n",
        "train_loader = DocumentSentimentDataLoader(dataset=train_dataset, max_seq_len=512, batch_size=32, num_workers=16, shuffle=True)  \n",
        "valid_loader = DocumentSentimentDataLoader(dataset=valid_dataset, max_seq_len=512, batch_size=32, num_workers=16, shuffle=False)  \n",
        "test_loader = DocumentSentimentDataLoader(dataset=test_dataset, max_seq_len=512, batch_size=32, num_workers=16, shuffle=False)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am1Fz4pQzhyw",
        "outputId": "0ee07004-88cc-48c9-eb55-7ec294454383"
      },
      "source": [
        "w2i, i2w = DocumentSentimentDataset.LABEL2INDEX, DocumentSentimentDataset.INDEX2LABEL\n",
        "print(w2i)\n",
        "print(i2w)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Positive': 0, 'Neutral': 1, 'Negative': 2, 'Irrelevant': 3}\n",
            "{0: 'Positive', 1: 'Neutral', 2: 'Negative', 3: 'Irrelevant'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "QSAsg9p0FAW2",
        "outputId": "50943b06-10c1-41f1-ee49-3a83ecb01fa7"
      },
      "source": [
        "train_dataset.data.loc[train_dataset.data.text.isna()]"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [sentiment, text]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIwMPpZSFaD1"
      },
      "source": [
        " for batch in train_loader:\n",
        "   break"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9KmZh9uzhyx"
      },
      "source": [
        "# Test model on sample sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6yxS2rCzhyx",
        "outputId": "82af28bb-b764-4aa4-f38d-4ab1038fb9dc"
      },
      "source": [
        "# negative\n",
        "text = '@Borderlands how do I submit a complaint? Your CEO isnt paying his staff their bonuses.'\n",
        "subwords = tokenizer.encode(text)\n",
        "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
        "\n",
        "logits = model(subwords)[0]\n",
        "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
        "\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: @Borderlands how do I submit a complaint? Your CEO isnt paying his staff their bonuses. | Label : Positive (29.979%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcTaiPNgzhyx",
        "outputId": "d4a06da0-70b2-4083-ba01-ccc715fe52da"
      },
      "source": [
        "# Neutral \n",
        "text = 'BITCH ASS LEGEND VIPâ€™D MY LITTLE BROTHER ON OUR 2 GAME WIN STREAK SMFH @Ronnie2K @NBA2K pic.twitter.com/GdS3KN9jVj'\n",
        "subwords = tokenizer.encode(text)\n",
        "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
        "\n",
        "logits = model(subwords)[0]\n",
        "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
        "\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: BITCH ASS LEGEND VIPâ€™D MY LITTLE BROTHER ON OUR 2 GAME WIN STREAK SMFH @Ronnie2K @NBA2K pic.twitter.com/GdS3KN9jVj | Label : Positive (30.881%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBaalPYAzhyy",
        "outputId": "bd9cdb2a-5ff1-408b-ebfc-ca3082ef7d79"
      },
      "source": [
        "# positive\n",
        "text = '3.7k to 3.2k ðŸ™ƒ I LOVE DOTA 2 PUTANG INA'\n",
        "subwords = tokenizer.encode(text)\n",
        "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
        "\n",
        "logits = model(subwords)[0]\n",
        "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
        "\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 3.7k to 3.2k ðŸ™ƒ I LOVE DOTA 2 PUTANG INA | Label : Positive (32.881%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uslv4ZqBzhyy"
      },
      "source": [
        "# Fine Tuning & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXoH-BNszhyy"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "model = model.cuda()"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4cj3tWNzhyy",
        "outputId": "13b1edbe-2784-45b2-fd3c-767225258b0f"
      },
      "source": [
        "# Train\n",
        "n_epochs = 10\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    torch.set_grad_enabled(True)\n",
        " \n",
        "    total_train_loss = 0\n",
        "    list_hyp, list_label = [], []\n",
        "\n",
        "    train_pbar = tqdm(train_loader, leave=True, total=len(train_loader))\n",
        "    for i, batch_data in enumerate(train_pbar):\n",
        "        # Forward model\n",
        "        loss, batch_hyp, batch_label = forward_sequence_classification(model, batch_data[:-1], i2w=i2w, device='cuda')\n",
        "\n",
        "        # Update model\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        tr_loss = loss.item()\n",
        "        total_train_loss = total_train_loss + tr_loss\n",
        "\n",
        "        # Calculate metrics\n",
        "        list_hyp += batch_hyp\n",
        "        list_label += batch_label\n",
        "\n",
        "        train_pbar.set_description(\"(Epoch {}) TRAIN LOSS:{:.4f} LR:{:.8f}\".format((epoch+1),\n",
        "            total_train_loss/(i+1), get_lr(optimizer)))\n",
        "\n",
        "    # Calculate train metric\n",
        "    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
        "    print(\"(Epoch {}) TRAIN LOSS:{:.4f} {} LR:{:.8f}\".format((epoch+1),\n",
        "        total_train_loss/(i+1), metrics_to_string(metrics), get_lr(optimizer)))\n",
        "\n",
        "    # Evaluate on validation\n",
        "    model.eval()\n",
        "    torch.set_grad_enabled(False)\n",
        "    \n",
        "    total_loss, total_correct, total_labels = 0, 0, 0\n",
        "    list_hyp, list_label = [], []\n",
        "\n",
        "    pbar = tqdm(valid_loader, leave=True, total=len(valid_loader))\n",
        "    for i, batch_data in enumerate(pbar):\n",
        "        batch_seq = batch_data[-1]        \n",
        "        loss, batch_hyp, batch_label = forward_sequence_classification(model, batch_data[:-1], i2w=i2w, device='cuda')\n",
        "        \n",
        "        # Calculate total loss\n",
        "        valid_loss = loss.item()\n",
        "        total_loss = total_loss + valid_loss\n",
        "\n",
        "        # Calculate evaluation metrics\n",
        "        list_hyp += batch_hyp\n",
        "        list_label += batch_label\n",
        "        # metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
        "\n",
        "        pbar.set_description(\"VALID LOSS:{:.4f}\".format(total_loss/(i+1)))\n",
        "        \n",
        "    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
        "    print(\"(Epoch {}) VALID LOSS:{:.4f} {}\".format((epoch+1),\n",
        "        total_loss/(i+1), metrics_to_string(metrics)))"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(Epoch 1) TRAIN LOSS:1.0200 LR:0.00010000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1850/1850 [01:30<00:00, 20.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 1) TRAIN LOSS:1.0200 ACC:0.58 F1:0.55 REC:0.55 PRE:0.57 LR:0.00010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VALID LOSS:0.7786: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 463/463 [00:16<00:00, 27.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 1) VALID LOSS:0.7786 ACC:0.70 F1:0.69 REC:0.69 PRE:0.69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(Epoch 2) TRAIN LOSS:0.6499 LR:0.00010000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1850/1850 [01:30<00:00, 20.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 2) TRAIN LOSS:0.6499 ACC:0.76 F1:0.75 REC:0.75 PRE:0.75 LR:0.00010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VALID LOSS:0.5677: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 463/463 [00:16<00:00, 27.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 2) VALID LOSS:0.5677 ACC:0.79 F1:0.78 REC:0.78 PRE:0.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(Epoch 3) TRAIN LOSS:0.4418 LR:0.00010000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1850/1850 [01:30<00:00, 20.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 3) TRAIN LOSS:0.4418 ACC:0.84 F1:0.83 REC:0.83 PRE:0.84 LR:0.00010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VALID LOSS:0.4590: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 463/463 [00:16<00:00, 27.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 3) VALID LOSS:0.4590 ACC:0.83 F1:0.83 REC:0.83 PRE:0.83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(Epoch 4) TRAIN LOSS:0.3307 LR:0.00010000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1850/1850 [01:29<00:00, 20.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 4) TRAIN LOSS:0.3307 ACC:0.88 F1:0.88 REC:0.87 PRE:0.88 LR:0.00010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VALID LOSS:0.4071: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 463/463 [00:16<00:00, 27.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 4) VALID LOSS:0.4071 ACC:0.86 F1:0.86 REC:0.85 PRE:0.87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(Epoch 5) TRAIN LOSS:0.2662 LR:0.00010000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1850/1850 [01:29<00:00, 20.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 5) TRAIN LOSS:0.2662 ACC:0.90 F1:0.90 REC:0.90 PRE:0.90 LR:0.00010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VALID LOSS:0.4024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 463/463 [00:16<00:00, 27.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 5) VALID LOSS:0.4024 ACC:0.87 F1:0.86 REC:0.86 PRE:0.87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(Epoch 6) TRAIN LOSS:0.2242 LR:0.00010000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1850/1850 [01:29<00:00, 20.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 6) TRAIN LOSS:0.2242 ACC:0.92 F1:0.92 REC:0.91 PRE:0.92 LR:0.00010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VALID LOSS:0.3707: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 463/463 [00:16<00:00, 28.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 6) VALID LOSS:0.3707 ACC:0.88 F1:0.88 REC:0.88 PRE:0.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(Epoch 7) TRAIN LOSS:0.1877 LR:0.00010000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1850/1850 [01:30<00:00, 20.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 7) TRAIN LOSS:0.1877 ACC:0.93 F1:0.93 REC:0.93 PRE:0.93 LR:0.00010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VALID LOSS:0.3584: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 463/463 [00:16<00:00, 27.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 7) VALID LOSS:0.3584 ACC:0.89 F1:0.88 REC:0.88 PRE:0.89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(Epoch 8) TRAIN LOSS:0.1666 LR:0.00010000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1850/1850 [01:30<00:00, 20.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 8) TRAIN LOSS:0.1666 ACC:0.94 F1:0.94 REC:0.93 PRE:0.94 LR:0.00010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VALID LOSS:0.3563: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 463/463 [00:17<00:00, 27.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 8) VALID LOSS:0.3563 ACC:0.89 F1:0.89 REC:0.89 PRE:0.89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(Epoch 9) TRAIN LOSS:0.1482 LR:0.00010000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1850/1850 [01:31<00:00, 20.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 9) TRAIN LOSS:0.1482 ACC:0.94 F1:0.94 REC:0.94 PRE:0.94 LR:0.00010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VALID LOSS:0.3559: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 463/463 [00:16<00:00, 27.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 9) VALID LOSS:0.3559 ACC:0.89 F1:0.89 REC:0.89 PRE:0.90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(Epoch 10) TRAIN LOSS:0.1347 LR:0.00010000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1850/1850 [01:30<00:00, 20.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 10) TRAIN LOSS:0.1347 ACC:0.95 F1:0.95 REC:0.95 PRE:0.95 LR:0.00010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VALID LOSS:0.3636: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 463/463 [00:17<00:00, 26.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 10) VALID LOSS:0.3636 ACC:0.90 F1:0.89 REC:0.89 PRE:0.90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmVJnFCXzhyz",
        "outputId": "9049698c-21a1-41c3-fdc4-0bf24227c412"
      },
      "source": [
        "# Evaluate on test\n",
        "model.eval()\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "total_loss, total_correct, total_labels = 0, 0, 0\n",
        "list_hyp, list_label = [], []\n",
        "\n",
        "pbar = tqdm(test_loader, leave=True, total=len(test_loader))\n",
        "for i, batch_data in enumerate(pbar):\n",
        "    _, batch_hyp, _ = forward_sequence_classification(model, batch_data[:-1], i2w=i2w, device='cuda')\n",
        "    list_hyp += batch_hyp\n",
        "\n",
        "# Save prediction\n",
        "df = pd.DataFrame({'label':list_hyp}).reset_index()\n",
        "df.to_csv('pred.txt', index=False)\n",
        "\n",
        "print(df)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 14.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     index       label\n",
            "0        0  Irrelevant\n",
            "1        1     Neutral\n",
            "2        2    Negative\n",
            "3        3    Negative\n",
            "4        4     Neutral\n",
            "..     ...         ...\n",
            "995    995  Irrelevant\n",
            "996    996  Irrelevant\n",
            "997    997    Positive\n",
            "998    998    Positive\n",
            "999    999     Neutral\n",
            "\n",
            "[1000 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htoJVgI7j4ne"
      },
      "source": [
        "# Accuracy on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud2zslPLUFmj"
      },
      "source": [
        "prediction = pd.read_csv('./pred.txt')"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V21sD6E0llIy",
        "outputId": "801d24ae-e093-4180-a810-cf723c890169"
      },
      "source": [
        "accuracy_score(test['sentiment'], prediction['label'])"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.941"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfI8SwuKj34s"
      },
      "source": [
        "#Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdjxQ7d1kzkB"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "ENZzajewk2TV",
        "outputId": "d53a5c6f-565e-4f33-9c77-ba5550a582be"
      },
      "source": [
        "y_unique = list(set(prediction['label']))\n",
        "cm = confusion_matrix(test['sentiment'], prediction['label'], labels = y_unique, normalize='true')\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=y_unique)\n",
        "disp.plot()"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f6d7f5f0450>"
            ]
          },
          "metadata": {},
          "execution_count": 183
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snIS1JWNzhy0"
      },
      "source": [
        "# Test fine-tuned model on sample sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAAjNx4Zzhy0",
        "outputId": "e7dfedfa-849c-4c5a-9d7f-a378c0ac6a08"
      },
      "source": [
        "# negative\n",
        "text = '@Borderlands how do I submit a complaint? Your CEO isnt paying his staff their bonuses.'\n",
        "subwords = tokenizer.encode(text)\n",
        "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
        "\n",
        "logits = model(subwords)[0]\n",
        "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
        "\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: @Borderlands how do I submit a complaint? Your CEO isnt paying his staff their bonuses. | Label : Negative (99.921%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1SGFtEhzhy0",
        "outputId": "bd0d26df-314e-4dbd-9be0-2371b172a934"
      },
      "source": [
        "# positive\n",
        "text = '3.7k to 3.2k ðŸ™ƒ I LOVE DOTA 2 PUTANG INA'\n",
        "subwords = tokenizer.encode(text)\n",
        "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
        "\n",
        "logits = model(subwords)[0]\n",
        "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
        "\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 3.7k to 3.2k ðŸ™ƒ I LOVE DOTA 2 PUTANG INA | Label : Positive (99.820%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkdNTfFgzhy1",
        "outputId": "31f76f96-f5b1-4e91-9518-599c0aa973d1"
      },
      "source": [
        "# negative \n",
        "text = 'FIX IT JESUS ! Please FIX IT ! What In the world is going on here.  @PlayStation @AskPlayStation @Playstationsup @Treyarch @CallofDuty negative 345 silver wolf error code pic.twitter.com/ziRyhrf59Q'\n",
        "subwords = tokenizer.encode(text)\n",
        "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
        "\n",
        "logits = model(subwords)[0]\n",
        "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
        "\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: FIX IT JESUS ! Please FIX IT ! What In the world is going on here.  @PlayStation @AskPlayStation @Playstationsup @Treyarch @CallofDuty negative 345 silver wolf error code pic.twitter.com/ziRyhrf59Q | Label : Negative (98.502%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Gq97vRO1Vs",
        "outputId": "c1ac1939-9fa0-42df-86af-2022ae4e9f37"
      },
      "source": [
        "# Neutral \n",
        "text = 'BITCH ASS LEGEND VIPâ€™D MY LITTLE BROTHER ON OUR 2 GAME WIN STREAK SMFH @Ronnie2K @NBA2K pic.twitter.com/GdS3KN9jVj'\n",
        "subwords = tokenizer.encode(text)\n",
        "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
        "\n",
        "logits = model(subwords)[0]\n",
        "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
        "\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: BITCH ASS LEGEND VIPâ€™D MY LITTLE BROTHER ON OUR 2 GAME WIN STREAK SMFH @Ronnie2K @NBA2K pic.twitter.com/GdS3KN9jVj | Label : Neutral (99.472%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JnNcM4zO8j5",
        "outputId": "11bd7c0d-f12f-40fa-e687-6afc830d060b"
      },
      "source": [
        "# irrelevant\n",
        "text = '10 year olds trading on the stock market is scary news. It can instill good financial habits/curiosity. BUT. Equally high chances of it going the opposite way: seeding gambling tendencies, heavy losses from trading F&Os, or worse - this becoming the next Blue Whale. Not worth it.'\n",
        "subwords = tokenizer.encode(text)\n",
        "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
        "\n",
        "logits = model(subwords)[0]\n",
        "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
        "\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 10 year olds trading on the stock market is scary news. It can instill good financial habits/curiosity. BUT. Equally high chances of it going the opposite way: seeding gambling tendencies, heavy losses from trading F&Os, or worse - this becoming the next Blue Whale. Not worth it. | Label : Irrelevant (99.912%)\n"
          ]
        }
      ]
    }
  ]
}